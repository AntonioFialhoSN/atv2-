O projeto tem como objetivo:
- Este trabalho individual visa explorar o impacto da taxa de aprendizado (α) e da inicialização dos parâmetros (θ inicial) no comportamento do algoritmo de descida do gradiente para regressão linear, bem como a implementação dos componentes básicos da regressão linear.
- Os objetivos específicos são:
    + Avaliar a influência da taxa de aprendizado na convergência da função custo.
    + Analisar a importância da inicialização dos pesos (θ) e suas implicações no processo de aprendizagem.
    + Implementar os componentes fundamentais do algoritmo de regressão linear para consolidar o entendimento teórico e prático:
    + warm_up_exercise.py: exercícios de aquecimentos com matriz identidade
    + plot_data.py: visualização gráfica dos dados
    + compute_cost.py: cálculo da função de custo J(θ)
    + gradient_descent.py: execução da descida do gradiente

Relatório de Atividades – Regressão Linear com Gradiente Descendente

Neste trabalho, inicialmente busquei entender qual era o objetivo da atividade. Após analisar os enunciados e o código fornecido, percebi que o foco era a implementação e compreensão de uma regressão linear utilizando o método de descida do gradiente.

O assunto central gira em torno da função de custo (mean squared error) e do algoritmo de gradient descent, que são fundamentais para ajustar os parâmetros do modelo e minimizar o erro entre as previsões e os valores reais.

Passei a analisar o código das funções envolvidas, especialmente a compute_cost, responsável por calcular o erro médio quadrático, e a gradient_descent, que ajusta os parâmetros theta iterativamente. Também estudei funções auxiliares que ajudam a visualizar os dados e estruturar o modelo, como warm_up_exercise3, warm_up_exercise4, e warm_up_exercise5.

Implementei o código conforme os espaços a serem preenchidos, testei os resultados e acompanhei a evolução do custo ao longo das iterações. A cada iteração, o custo foi diminuindo, o que indicou que o modelo estava aprendendo.

Além disso, compreendi que a adição do termo de bias (coluna de 1s), a predição com X @ theta, e o cálculo do gradiente são passos essenciais na construção da regressão linear.



Para o professor:
Prezados,

Gostaria de relatar uma dificuldade técnica encontrada durante a execução do trabalho. Ao tentar acessar o pacote Office através do link institucional disponibilizado, verifiquei que não havia produtos disponíveis para utilização em minha conta.

Diante desse impasse, adotei uma solução alternativa utilizando o Google Docs. Para garantir o registro adequado das alterações, compartilhei o documento com uma conta privada secundária. Dessa forma, todas as edições realizadas pela conta institucional ficaram devidamente registradas na aba "Histórico de versões" e "Comentários" da plataforma.

Segue o link do documento para referência:

https://docs.google.com/document/d/1CYECWxwq_mpWdgRVrv88OR2j7HBEVZn4OxY0nShma_U/edit?usp=sharing



